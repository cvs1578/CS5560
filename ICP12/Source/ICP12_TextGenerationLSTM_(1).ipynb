{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP12_TextGenerationLSTM (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvo6KpuqNuOL",
        "outputId": "13b2985f-8b0f-4fa7-dcd6-7af185e664fa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slJv_my5DAdG"
      },
      "source": [
        "Let's start out by importing all the libraries we're going to use.\n",
        "\n",
        "We need numpy to transform our input data into arrays our network can use, and we'll obviously be using several functions from Keras.\n",
        "\n",
        "We'll also need to use some functions from the Natural Language Toolkit (NLTK) to preprocess our text and get it ready to train on. Finally, we'll need the sys library to handle the printing of our text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF9-jJhR_BxM",
        "outputId": "fa7cbee9-29aa-4e64-9bac-2a261f6536ff"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sympy import ifft\n",
        "#Everything below here was in the example and I'm too afriad to remove them\n",
        "import requests\n",
        "import sys\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3XlznQ-DuBi"
      },
      "source": [
        "Lets verify the data is proprely read. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "w_aVhaOT_pxI",
        "outputId": "4da6d1f0-ea4d-4a3d-b592-468a3ea87a05"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ICP12/AAPL_2006-01-01_to_2018-01-01.csv\")\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006-01-03</td>\n",
              "      <td>10.34</td>\n",
              "      <td>10.68</td>\n",
              "      <td>10.32</td>\n",
              "      <td>10.68</td>\n",
              "      <td>201853036</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2006-01-04</td>\n",
              "      <td>10.73</td>\n",
              "      <td>10.85</td>\n",
              "      <td>10.64</td>\n",
              "      <td>10.71</td>\n",
              "      <td>155225609</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2006-01-05</td>\n",
              "      <td>10.69</td>\n",
              "      <td>10.70</td>\n",
              "      <td>10.54</td>\n",
              "      <td>10.63</td>\n",
              "      <td>112396081</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2006-01-06</td>\n",
              "      <td>10.75</td>\n",
              "      <td>10.96</td>\n",
              "      <td>10.65</td>\n",
              "      <td>10.90</td>\n",
              "      <td>176139334</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006-01-09</td>\n",
              "      <td>10.96</td>\n",
              "      <td>11.03</td>\n",
              "      <td>10.82</td>\n",
              "      <td>10.86</td>\n",
              "      <td>168861224</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3014</th>\n",
              "      <td>2017-12-22</td>\n",
              "      <td>174.68</td>\n",
              "      <td>175.42</td>\n",
              "      <td>174.50</td>\n",
              "      <td>175.01</td>\n",
              "      <td>16349444</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3015</th>\n",
              "      <td>2017-12-26</td>\n",
              "      <td>170.80</td>\n",
              "      <td>171.47</td>\n",
              "      <td>169.68</td>\n",
              "      <td>170.57</td>\n",
              "      <td>33185536</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3016</th>\n",
              "      <td>2017-12-27</td>\n",
              "      <td>170.10</td>\n",
              "      <td>170.78</td>\n",
              "      <td>169.71</td>\n",
              "      <td>170.60</td>\n",
              "      <td>21498213</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3017</th>\n",
              "      <td>2017-12-28</td>\n",
              "      <td>171.00</td>\n",
              "      <td>171.85</td>\n",
              "      <td>170.48</td>\n",
              "      <td>171.08</td>\n",
              "      <td>16480187</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3018</th>\n",
              "      <td>2017-12-29</td>\n",
              "      <td>170.52</td>\n",
              "      <td>170.59</td>\n",
              "      <td>169.22</td>\n",
              "      <td>169.23</td>\n",
              "      <td>25999922</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3019 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date    Open    High     Low   Close     Volume  Name\n",
              "0     2006-01-03   10.34   10.68   10.32   10.68  201853036  AAPL\n",
              "1     2006-01-04   10.73   10.85   10.64   10.71  155225609  AAPL\n",
              "2     2006-01-05   10.69   10.70   10.54   10.63  112396081  AAPL\n",
              "3     2006-01-06   10.75   10.96   10.65   10.90  176139334  AAPL\n",
              "4     2006-01-09   10.96   11.03   10.82   10.86  168861224  AAPL\n",
              "...          ...     ...     ...     ...     ...        ...   ...\n",
              "3014  2017-12-22  174.68  175.42  174.50  175.01   16349444  AAPL\n",
              "3015  2017-12-26  170.80  171.47  169.68  170.57   33185536  AAPL\n",
              "3016  2017-12-27  170.10  170.78  169.71  170.60   21498213  AAPL\n",
              "3017  2017-12-28  171.00  171.85  170.48  171.08   16480187  AAPL\n",
              "3018  2017-12-29  170.52  170.59  169.22  169.23   25999922  AAPL\n",
              "\n",
              "[3019 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS6LpcKBD811"
      },
      "source": [
        "Let's start by loading in our text data and doing some preprocessing of the data. For this data, we are only gonna care about the 'Close'.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuPYutWz_qqf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "1c5e39f7-93bf-45d8-c4d9-c0244d2d8662"
      },
      "source": [
        "data= df[['Close']]\n",
        "data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3014</th>\n",
              "      <td>175.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3015</th>\n",
              "      <td>170.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3016</th>\n",
              "      <td>170.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3017</th>\n",
              "      <td>171.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3018</th>\n",
              "      <td>169.23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3019 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Close\n",
              "0      10.68\n",
              "1      10.71\n",
              "2      10.63\n",
              "3      10.90\n",
              "4      10.86\n",
              "...      ...\n",
              "3014  175.01\n",
              "3015  170.57\n",
              "3016  170.60\n",
              "3017  171.08\n",
              "3018  169.23\n",
              "\n",
              "[3019 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJYOOmIxGOc7"
      },
      "source": [
        "Separate into training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngrbannIWnCt"
      },
      "source": [
        "training = data.iloc[:2900]\n",
        "test = data.iloc[2900:] #Only have 100 to test. More training = more accurate (theoretically)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0G0BknEGPIq"
      },
      "source": [
        "Now we'll go ahead and convert our input sequences into a processed numpy array that our network can use. We'll also need to convert the numpy array values into floats so that the sigmoid activation function our network uses can interpret them and output probabilities from 0 to 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWbBhVAaGPaf"
      },
      "source": [
        "#Have to scale the data first because it won't work correctly without it\n",
        "scale = MinMaxScaler();\n",
        "training = scale.fit_transform(training);\n",
        "#Next we're putting in x(t) and y(t+1)\n",
        "X = []\n",
        "y = []\n",
        "for i in range (len(training)-1):\n",
        "  X.append(training[i])\n",
        "  y.append(training[i+1])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhW4lkRWcMtp"
      },
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "X = np.reshape(X, (X.shape[0],X.shape[1],1)) #Need to reshape for model to work"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQWFxfaJGRD4"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], 1), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[0], activation='softmax'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLukcjelGRy4"
      },
      "source": [
        "We compile the model now, and it is ready for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSgz-LAqGSHg"
      },
      "source": [
        "model.compile(loss='mean_squared_error', optimizer='adam') \n",
        "#meansquarederror because examples I found online calculated the actual MSE and \n",
        "#this is easier"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGvSpUjTJbRd"
      },
      "source": [
        "desired_callbacks= ModelCheckpoint('model_saved_weights.h5', monitor='loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh9pSQ4EH8k4"
      },
      "source": [
        "Now we'll fit the model and let it train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMuINLtwH85J",
        "outputId": "629962d1-8693-43f5-98fa-71d57749d480"
      },
      "source": [
        "model.fit(X, y, epochs=200, batch_size=256)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "12/12 [==============================] - 6s 6ms/step - loss: 0.2068\n",
            "Epoch 2/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2074\n",
            "Epoch 3/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2016\n",
            "Epoch 4/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2043\n",
            "Epoch 5/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1970\n",
            "Epoch 6/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2125\n",
            "Epoch 7/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2009\n",
            "Epoch 8/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1981\n",
            "Epoch 9/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2069\n",
            "Epoch 10/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2020\n",
            "Epoch 11/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2041\n",
            "Epoch 12/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2048\n",
            "Epoch 13/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2087\n",
            "Epoch 14/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1999\n",
            "Epoch 15/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2074\n",
            "Epoch 16/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2069\n",
            "Epoch 17/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2020\n",
            "Epoch 18/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2040\n",
            "Epoch 19/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2044\n",
            "Epoch 20/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2027\n",
            "Epoch 21/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1979\n",
            "Epoch 22/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2068\n",
            "Epoch 23/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2065\n",
            "Epoch 24/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2058\n",
            "Epoch 25/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2017\n",
            "Epoch 26/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2022\n",
            "Epoch 27/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2001\n",
            "Epoch 28/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2097\n",
            "Epoch 29/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2005\n",
            "Epoch 30/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2070\n",
            "Epoch 31/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2033\n",
            "Epoch 32/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2037\n",
            "Epoch 33/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2011\n",
            "Epoch 34/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2044\n",
            "Epoch 35/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2013\n",
            "Epoch 36/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2005\n",
            "Epoch 37/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2038\n",
            "Epoch 38/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2026\n",
            "Epoch 39/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1984\n",
            "Epoch 40/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2042\n",
            "Epoch 41/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2087\n",
            "Epoch 42/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2010\n",
            "Epoch 43/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2061\n",
            "Epoch 44/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2041\n",
            "Epoch 45/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2045\n",
            "Epoch 46/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2054\n",
            "Epoch 47/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2015\n",
            "Epoch 48/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2007\n",
            "Epoch 49/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2037\n",
            "Epoch 50/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1959\n",
            "Epoch 51/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1969\n",
            "Epoch 52/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2035\n",
            "Epoch 53/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2055\n",
            "Epoch 54/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2037\n",
            "Epoch 55/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2000\n",
            "Epoch 56/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2069\n",
            "Epoch 57/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1957\n",
            "Epoch 58/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1994\n",
            "Epoch 59/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2080\n",
            "Epoch 60/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2002\n",
            "Epoch 61/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2043\n",
            "Epoch 62/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2014\n",
            "Epoch 63/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2015\n",
            "Epoch 64/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2055\n",
            "Epoch 65/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2051\n",
            "Epoch 66/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2048\n",
            "Epoch 67/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2037\n",
            "Epoch 68/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2056\n",
            "Epoch 69/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2029\n",
            "Epoch 70/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1995\n",
            "Epoch 71/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2017\n",
            "Epoch 72/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1999\n",
            "Epoch 73/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2052\n",
            "Epoch 74/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2000\n",
            "Epoch 75/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2039\n",
            "Epoch 76/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2049\n",
            "Epoch 77/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2094\n",
            "Epoch 78/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2011\n",
            "Epoch 79/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2018\n",
            "Epoch 80/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2055\n",
            "Epoch 81/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2052\n",
            "Epoch 82/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2069\n",
            "Epoch 83/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2060\n",
            "Epoch 84/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2028\n",
            "Epoch 85/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2088\n",
            "Epoch 86/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2017\n",
            "Epoch 87/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2057\n",
            "Epoch 88/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2081\n",
            "Epoch 89/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2038\n",
            "Epoch 90/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2063\n",
            "Epoch 91/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2029\n",
            "Epoch 92/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2111\n",
            "Epoch 93/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2013\n",
            "Epoch 94/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2059\n",
            "Epoch 95/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2028\n",
            "Epoch 96/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2085\n",
            "Epoch 97/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2027\n",
            "Epoch 98/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2094\n",
            "Epoch 99/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2043\n",
            "Epoch 100/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2089\n",
            "Epoch 101/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2069\n",
            "Epoch 102/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2034\n",
            "Epoch 103/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2006\n",
            "Epoch 104/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2081\n",
            "Epoch 105/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2018\n",
            "Epoch 106/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2087\n",
            "Epoch 107/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2047\n",
            "Epoch 108/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2135\n",
            "Epoch 109/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2079\n",
            "Epoch 110/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2058\n",
            "Epoch 111/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2106\n",
            "Epoch 112/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2035\n",
            "Epoch 113/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2026\n",
            "Epoch 114/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2056\n",
            "Epoch 115/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2049\n",
            "Epoch 116/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2017\n",
            "Epoch 117/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2052\n",
            "Epoch 118/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2048\n",
            "Epoch 119/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2003\n",
            "Epoch 120/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2052\n",
            "Epoch 121/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2044\n",
            "Epoch 122/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1969\n",
            "Epoch 123/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2037\n",
            "Epoch 124/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2029\n",
            "Epoch 125/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2023\n",
            "Epoch 126/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1997\n",
            "Epoch 127/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2063\n",
            "Epoch 128/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2038\n",
            "Epoch 129/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2077\n",
            "Epoch 130/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1972\n",
            "Epoch 131/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2061\n",
            "Epoch 132/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2052\n",
            "Epoch 133/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2032\n",
            "Epoch 134/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2019\n",
            "Epoch 135/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2090\n",
            "Epoch 136/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2024\n",
            "Epoch 137/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2017\n",
            "Epoch 138/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2019\n",
            "Epoch 139/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1969\n",
            "Epoch 140/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2073\n",
            "Epoch 141/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2042\n",
            "Epoch 142/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2031\n",
            "Epoch 143/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2040\n",
            "Epoch 144/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2046\n",
            "Epoch 145/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2032\n",
            "Epoch 146/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2036\n",
            "Epoch 147/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2000\n",
            "Epoch 148/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2025\n",
            "Epoch 149/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2028\n",
            "Epoch 150/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2016\n",
            "Epoch 151/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2034\n",
            "Epoch 152/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2038\n",
            "Epoch 153/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2004\n",
            "Epoch 154/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2017\n",
            "Epoch 155/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2046\n",
            "Epoch 156/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2019\n",
            "Epoch 157/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2080\n",
            "Epoch 158/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2077\n",
            "Epoch 159/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2031\n",
            "Epoch 160/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2019\n",
            "Epoch 161/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1987\n",
            "Epoch 162/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1984\n",
            "Epoch 163/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2026\n",
            "Epoch 164/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2054\n",
            "Epoch 165/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1989\n",
            "Epoch 166/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2071\n",
            "Epoch 167/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2027\n",
            "Epoch 168/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2066\n",
            "Epoch 169/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2011\n",
            "Epoch 170/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1990\n",
            "Epoch 171/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2019\n",
            "Epoch 172/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2016\n",
            "Epoch 173/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2057\n",
            "Epoch 174/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1985\n",
            "Epoch 175/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2040\n",
            "Epoch 176/200\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2085\n",
            "Epoch 177/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1982\n",
            "Epoch 178/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2038\n",
            "Epoch 179/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1974\n",
            "Epoch 180/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1977\n",
            "Epoch 181/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2015\n",
            "Epoch 182/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2022\n",
            "Epoch 183/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1994\n",
            "Epoch 184/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2016\n",
            "Epoch 185/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2054\n",
            "Epoch 186/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2011\n",
            "Epoch 187/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2082\n",
            "Epoch 188/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2044\n",
            "Epoch 189/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2015\n",
            "Epoch 190/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2037\n",
            "Epoch 191/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2073\n",
            "Epoch 192/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2097\n",
            "Epoch 193/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1984\n",
            "Epoch 194/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2034\n",
            "Epoch 195/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2014\n",
            "Epoch 196/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2017\n",
            "Epoch 197/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2062\n",
            "Epoch 198/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1983\n",
            "Epoch 199/200\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2028\n",
            "Epoch 200/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5b9023bb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPrhmAo2KfJb"
      },
      "source": [
        "#Next it's time to analyze the model. First, we normalize the testing \n",
        "#Like we did with the training\n",
        "test = scale.fit_transform(test);\n",
        "X_test = []\n",
        "for i in range (len(test)):\n",
        "  X_test.append(test[i])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0],1,X_test.shape[1]))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTUEPESxjZCt"
      },
      "source": [
        "#Now we predict the model, taking the inverse of \n",
        "#Both the prediction and test so data is readable.\n",
        "predict = model.predict(X_test)\n",
        "predict = scale.inverse_transform(predict)\n",
        "test = scale.inverse_transform(test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "MRD5DAw_lOqD",
        "outputId": "b10ce485-14b4-48e5-c36c-6da557629a23"
      },
      "source": [
        "#Results don't look good. Something wrong with model\n",
        "plt.plot(df.loc[2900:,'Date'],predict, color = \"green\")\n",
        "plt.plot(df.loc[2900:,'Date'],test, color = \"red\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5b7aa006d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}