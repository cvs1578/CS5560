{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6WsSxtoOg-S"
      },
      "source": [
        "TASK: Perform triplet extraction on the Abstracts and have Triplets ready for ontology.\r\n",
        "\r\n",
        "\r\n",
        "NOTE: Using same code used in ICP3\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQKXc5sSP0EI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4b0ae1-4785-45ef-a650-7c8452c0fb58"
      },
      "source": [
        "!pip install textacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting textacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/99/054efc5dea92c84a850639c490541de6cba29bc148debc3c73848c5e64c2/textacy-0.10.1-py3-none-any.whl (183kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.4.1)\n",
            "Collecting jellyfish>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/a6/4d039bc827a102f62ce7a7910713e38fdfd7c7a40aa39c72fb14938a1473/jellyfish-0.8.2-cp37-cp37m-manylinux2014_x86_64.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.2.1)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.19.5)\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.2.4)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn<0.24.0,>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.22.2.post1)\n",
            "Collecting cytoolz>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/67/1c60da8ba831bfefedb64c78b9f6820bdf58972797c95644ee3191daf27a/cytoolz-0.11.0.tar.gz (477kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.0.5)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.5)\n",
            "Requirement already satisfied: pyemd>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (0.5.1)\n",
            "Collecting pyphen>=0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/5a/5bc036e01389bc6a6667a932bac3e388de6e7fa5777a6ff50e652f60ec79/Pyphen-0.10.0-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->textacy) (54.0.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz>=0.8.0->textacy) (0.11.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->textacy) (4.4.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.2.0->textacy) (3.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.2.0->textacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.2.0->textacy) (3.4.1)\n",
            "Building wheels for collected packages: cytoolz\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.11.0-cp37-cp37m-linux_x86_64.whl size=1223224 sha256=455be2bb8783711f8e05de961551fead9c9153a06aa28119d7c2674788b66bb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/32/3c/9c9926b510647cacdde744b2c7acdf1ccd5896fbb7f8d5df0c\n",
            "Successfully built cytoolz\n",
            "Installing collected packages: jellyfish, cytoolz, pyphen, textacy\n",
            "Successfully installed cytoolz-0.11.0 jellyfish-0.8.2 pyphen-0.10.0 textacy-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdS1EzrsP2Sm"
      },
      "source": [
        "#We are going to use Spacy in combination with Textacy since textacy has a verb_object_triples function\r\n",
        "import spacy\r\n",
        "import textacy\r\n",
        "nlp = spacy.load('en')\r\n",
        "\r\n",
        "#Here we are going to import all of the txt files\r\n",
        "\r\n",
        "file1 = open('/content/drive/MyDrive/Colab Notebooks/ICP8/DarthPlagueis.txt').read()\r\n",
        "file2 = open('/content/drive/MyDrive/Colab Notebooks/ICP8/ChristopherNolan.txt').read()\r\n",
        "file3 = open('/content/drive/MyDrive/Colab Notebooks/ICP8/RespectfulDriver.txt').read()\r\n",
        "\r\n",
        "\r\n",
        "#First, we must tokenize the words\r\n",
        "\r\n",
        "doc1 = nlp(file1)\r\n",
        "doc2 = nlp(file2)\r\n",
        "doc3 = nlp(file3)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvnR_qydP9GI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8371c08-5c2a-469d-fc82-ee1225489db1"
      },
      "source": [
        "#Next, we will just use the function in textacy that will output a generator that contains a list of the data\r\n",
        "print(\"Doc1\")\r\n",
        "Trip1 = textacy.extract.subject_verb_object_triples(doc1)\r\n",
        "for x in Trip1:\r\n",
        "  print (x)\r\n",
        "\r\n",
        "print(\"Doc2\")\r\n",
        "Trip2 = textacy.extract.subject_verb_object_triples(doc2)\r\n",
        "for x in Trip2:\r\n",
        "  print (x)\r\n",
        "\r\n",
        "print(\"Doc3\")\r\n",
        "Trip3 = textacy.extract.subject_verb_object_triples(doc3)\r\n",
        "for x in Trip3:\r\n",
        "  print (x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Doc1\n",
            "(you, hear, tragedy)\n",
            "(Jedi, would tell, you)\n",
            "(he, could use, Force)\n",
            "(he, could use, to influence)\n",
            "(he, keep, ones)\n",
            "(some, consider, be)\n",
            "(thing, was losing, power)\n",
            "(he, taught, apprentice)\n",
            "(he, taught, everything)\n",
            "(apprentice, killed, him)\n",
            "(He, could save, others)\n",
            "Doc2\n",
            "(he, compared, diagram)\n",
            "(plot, makes, sense)\n",
            "(I, ’ve watched, videos)\n",
            "(I, can’t make, heads)\n",
            "(I, can’t make, tails)\n",
            "Doc3\n",
            "(it, ’s, nothing)\n",
            "(It, ’s, reflex)\n",
            "(it, slows, everyone)\n",
            "(drivers, had stopped, cars)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}